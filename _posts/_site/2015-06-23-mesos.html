<h2 id="how-yodel-solved-its-deployment-problems-using-mesos-and-marathon-with-docker">How Yodel solved its deployment problems using Mesos and Marathon with Docker</h2>

<hr />

<h2 id="goals">Goals</h2>
<ul>
  <li>Enpower the developers no ops person</li>
  <li>Developer can set the deployment into the pipeline and go to lunch and come back</li>
</ul>

<h2 id="technologies-used">Technologies used</h2>
<p>Some of the technology used at yodel</p>

<h3 id="service-discovery">Service Discovery</h3>
<ul>
  <li>HA Proxy</li>
  <li>Qubit Bamboo</li>
</ul>

<h3 id="container">Container</h3>
<p>Docker</p>

<h3 id="schedulerkeepalive">Scheduler/keepalive</h3>
<ul>
  <li>Marathon - A Mesos scheduler and starts the process if mesos kill it</li>
  <li>Monitoring when processes are down and self-heal to bring up another instance</li>
</ul>

<h3 id="virtual-layer">Virtual layer</h3>
<p>#### Mesos #### 
1. Master slave topology
2. Clustering for realms
    * PROD mesos cluster
    * QA mesos clsuter
    * Staging mesos cluster
3. Contains zookeeper</p>

<h3 id="ci">CI</h3>
<p>Atlassian Bamboo - CI</p>

<h3 id="monitoring">Monitoring</h3>
<p>New Relics</p>

<h3 id="deploy-scripts">Deploy scripts</h3>
<p>In house microservice called “Cerebro” - microservice in docker container deployed by marathon in mesos</p>

<h3 id="configuration">Configuration</h3>
<p>docker file and puppet</p>

<h3 id="logs">Logs</h3>
<p>syslogs (or other sensible log solution) - trade off no console log</p>

<h3 id="scheduling">Scheduling</h3>
<p>MPI and Hadoop schedulers</p>

<h1 id="problems-faced-and-solutions">Problems faced and solutions</h1>

<h2 id="problem-bad-actors">Problem: Bad Actors</h2>
<p>Some processes cause starvation</p>

<h2 id="solution-dynamic-scalingcustomizable-services">Solution: dynamic scaling/customizable services</h2>

<h3 id="scaling">Scaling</h3>
<p>Scales from 3 to 3000 dyanmically, through an UI for example
  1. A process is not allowed to consume more than the resource CPU/Memory that is allocated
  2. No starvation</p>

<h3 id="resource-constraints">Resource constraints</h3>
<ol>
  <li>CPU (fall back to swap if set up) meso will kill and marathon will take over and startup</li>
  <li>Memory constraint is soft - if process is the only running on host it can consume all memory</li>
</ol>

<h3 id="problem-explicit-service-discovery">Problem: explicit service discovery</h3>
<ul>
  <li>Doesn’t need to contact zookeeper discovery to figure out QA and PROD</li>
</ul>

<h3 id="solution-implicit-service-discovery">Solution: implicit service discovery</h3>
<p>look up port 8080 and it distributes to the slaves that are 
service-instance-1 Listening on 31003
service-instance-2 Lisetning on 31090</p>

<h2 id="problem-all-or-nothing-deployment-is-a-problem">Problem: All or nothing deployment is a problem</h2>
<p>If there are problems in production you have to roll back</p>

<h2 id="solution-canary-deployments">Solution: Canary Deployments</h2>

<p><strong>Canary Isolated</strong>
  * Step your toe into PROD and see if it’s working
  * deploy to PROD tests are passing</p>

<p><strong>Canary Partial</strong>
  * Leg into PROD and see if it’s working
  * decree 10% of the traffic, if error rollback</p>

<p><strong>Full Production</strong>
  * deploy to PROD with confidence</p>

<h2 id="configuration-management">Configuration management</h2>
<p>Configuration management for infrastructure and application</p>

<h3 id="infrastructure-level">Infrastructure level</h3>
<p>puppet for configuration to manage (ex: a system admin)
mesos master and slave for infrastructure</p>

<h3 id="application-level">Application level</h3>
<p>developer configure their own docker file (ex: a java developer)</p>

<h2 id="clean-up">Clean up</h2>
<ol>
  <li>3 newers versions brought up, mesos will tear down the old versions and taken out of rotation once marathon verifies the new versions are up and running</li>
  <li>deployment finished the ‘cerebro’ deamon stops watching it, new relic take over</li>
</ol>

<h2 id="deployed-outside-of-mesos-clusters">Deployed outside of mesos clusters</h2>
<ol>
  <li>databases are mapped outside of mesos</li>
  <li>Legacy services
ex: using curator over zookeeper for thrift/legacy stack</li>
</ol>

<h2 id="alternatives-to-mesos">Alternatives to Mesos</h2>
<p>CoreOS
Fleet</p>

<h2 id="developer-environment">Developer environment</h2>
<ul>
  <li>Docker container</li>
  <li>No mesos in DEV but deploy the container over to mesos cluster</li>
</ul>

<h2 id="q--a">Q &amp; A</h2>

<ol>
  <li>Why Qubit Bamboo and HA Proxy?</li>
</ol>

<p><strong>HA Proxy for canary</strong>
  - waiting for canary partial
  - header for canary isolation</p>

<p><strong>Alternatives to Qubit Bamboo</strong>
  - Consul template instead Qubit Bamboo</p>

<ol>
  <li>Production topology
    <ul>
      <li>4 Mesos slaves and 4 mesos masters</li>
      <li>4 machines</li>
      <li>20 services 3 instances each</li>
      <li>60 docker containers</li>
    </ul>
  </li>
  <li>Chronos
    <ul>
      <li>being evaluated for scheduling to replace cron</li>
      <li>leader election is a horrible problem with shell script</li>
    </ul>
  </li>
  <li>Right now only long-running services
    <ul>
      <li>Short running batch processes shouldn’t conflict (hadoop)
  Constraint is resource CPU/memory</li>
    </ul>
  </li>
  <li>Reliable non-flaky deployments
    <ul>
      <li>“Cerebro” - in house runs as a docker container through Mesos</li>
      <li>micro service architecture - shared state is not a thing that happens as each service has its own database</li>
    </ul>
  </li>
  <li>Case study: Production process was falling over (memory issue)
    <ul>
      <li>Used canary isolated to continuously deploy and rollback</li>
    </ul>
  </li>
</ol>
